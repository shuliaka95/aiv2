# check_modulation.py
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from torchsig.datasets.datasets import TorchSigIterableDataset
from torchsig.datasets.dataset_metadata import DatasetMetadata
import numpy as np

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ 3 Ð¼Ð¾Ð´ÑƒÐ»ÑÑ†Ð¸Ð¸ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð°
mods = ['ook', 'bpsk', 'qpsk']

print("ðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° REAL Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð´ÑƒÐ»ÑÑ†Ð¸Ð¹ TorchSig")

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
metadata = DatasetMetadata(
    num_iq_samples_dataset=1024,
    fft_size=256,
    impairment_level=2.0,  # Ð”Ð¾Ð±Ð°Ð²Ð¸Ð¼ ÑˆÑƒÐ¼
    num_signals_max=1,
    num_signals_min=1,
    sample_rate=1e6,
    class_list=mods,
    enable_class_encoding=True,
)

dataset = TorchSigIterableDataset(
    dataset_metadata=metadata,
    processing_pipeline=[]  # Ð‘ÐµÐ· ÐºÐ°ÑÑ‚Ð¾Ð¼Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
)

print(f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÑƒÐ»ÑÑ†Ð¸Ð¸: {mods}")
labels_seen = []
raw_signals = []

# Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ 50 ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²
for i in range(50):
    try:
        signal = next(iter(dataset))
        raw_signals.append(signal)
        
        # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð½Ñ‹Ðµ ÑÐ¿Ð¾ÑÐ¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚ÐºÑƒ
        label = -1
        
        # Ð¡Ð¿Ð¾ÑÐ¾Ð± 1: Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚Ñ‹ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
        print(f"\nSignal {i+1} attributes:")
        print(f"  Type: {type(signal)}")
        print(f"  Dir: {[x for x in dir(signal) if not x.startswith('_')][:10]}")
        
        if hasattr(signal, 'class_idx'):
            label = signal.class_idx
            print(f"  class_idx: {label}")
        
        if hasattr(signal, 'component_signals'):
            print(f"  component_signals: {len(signal.component_signals)}")
            if signal.component_signals:
                comp = signal.component_signals[0]
                print(f"  Component type: {type(comp)}")
                if hasattr(comp, 'metadata'):
                    print(f"  Metadata dir: {[x for x in dir(comp.metadata) if not x.startswith('_')]}")
                    if hasattr(comp.metadata, 'class_idx'):
                        label = comp.metadata.class_idx
                        print(f"  metadata.class_idx: {label}")
                    if hasattr(comp.metadata, 'class_name'):
                        class_name = comp.metadata.class_name
                        print(f"  metadata.class_name: {class_name}")
                        # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð½Ð°Ð¹Ñ‚Ð¸ Ð² Ð½Ð°ÑˆÐµÐ¼ ÑÐ¿Ð¸ÑÐºÐµ
                        if class_name in mods:
                            label = mods.index(class_name)
        
        if label == -1:
            print(f"  âš ï¸ ÐÐµ Ð½Ð°ÑˆÐµÐ» Ð¼ÐµÑ‚ÐºÑƒ")
            label = 0
        
        labels_seen.append(label)
        print(f"  Final label: {label} -> {mods[label] if label < len(mods) else 'UNKNOWN'}")
        
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
        break

if labels_seen:
    print(f"\nðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¼ÐµÑ‚Ð¾Ðº Ð¸Ð· {len(labels_seen)} ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²:")
    label_counts = np.bincount(labels_seen, minlength=len(mods))
    for i, mod in enumerate(mods):
        print(f"  {mod}: {label_counts[i]} ({label_counts[i]/len(labels_seen)*100:.1f}%)")
else:
    print("âŒ ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ")
